---
title: Too Many Date Dimensions? Try Events!
excerpt: Take a look at your model from different perspective 
layout: post
---

# {{ page.title }}
_by ZD ([@zsvoboda](http://twitter.com/#!zsvoboda))_

Time can have many different meanings in analytical projects. For example an opportunity can be associated with the time when it was created and the time when a sales guy closed it. I saw quite a few models with way more times associated with a single entity (e.g. helpdesk models). Here is a typical example of a simple sales model that uses _created_ and _closed_ date dimensions.

![Sales Data Model]({{ site.root }}/images/posts/2011-06-24-events-original-ldm.png)

However end users have sometimes difficult time to figure out why there are two date dimensions and which one they should use in their reports. "There is only one time" they think. There is one more problem except the end user usability. 

You can easily create a report _Revenue by Time_ that is sliced by the _Closed Date_.

![Revenue by Time]({{ site.root }}/images/posts/2011-06-24-events-revenue-standard.png)

You can also create a report _Pipeline Generation by Time_ that is sliced by the _Created Date_.

![Pipeline by Time]({{ site.root }}/images/posts/2011-06-24-events-pipeline-standard.png)

But as the first report uses the _closed_ and the second report the _created_ time dimensions, you can't put both metrics to a single chart:

![Pipeline &amp; Revenue by Time]({{ site.root }}/images/posts/2011-06-24-events-pipeline-event.png)

You need to model your analytical project differently to achieve the report above. We are getting to something what we call event data models. Here you go:

![Sales Data Model (Event)]({{ site.root }}/images/posts/2011-06-24-events-event-ldm.png)

We need to create a special _Event_ dataset that contains all events related to a specific opportunity. In our case there are two events per each opportunity: _created_ &amp; _closed_ . The _Event_ dataset then has twice as much records as the original _Opportunity_ dataset. We obviously need to adjust the metrics to not return all amounts multiplied by two. Here are few metrics definitions:

- *Pipeline [Sum]*: <code>SELECT SUM(Event Amount) WHERE Event Type = created</code>
- *Revenue [Sum]*: <code>SELECT SUM(Event Amount) WHERE Event Type = closed AND Status IN (Won)</code>
- *Lost Revenue [Sum]*: <code>SELECT SUM(Event Amount) WHERE Event Type = closed AND Status IN (Lost)</code>

These metrics are relatively simple and self describing. The metrics that compute that last opportunity value are a bit more complicated. We need to always find the 'latest' available event for each opportunity in the _Event_ dataset. This is why we have the _Event ID_ FACT in the model. This fact is a unique ID of each event. The later an event occurred, the higher the _Event ID_ is. So the maximum _Event ID_ for a specific opportunity identifies the latest event for that opportunity. So we need to first compute this MAX ID.

- *Last Opportunity Event ID*: <code>SELECT MAX(Event ID) BY Opportunity ID ALL IN ALL OTHER DIMENSIONS</code>

then the current (latest) opportunity amount, revenue, and pipeline are:
 
- *Current Amount [Sum]*: <code>SELECT SUM(Event Amount) WHERE Event ID = Last Opportunity Event ID</code> 
- *Current Revenue [Sum]*: <code>SELECT Current Amount [Sum] WHERE Status = Won</code> 
- *Current Pipeline [Sum]*: <code>SELECT Current Amount [Sum] WHERE Status = Open</code> 
- *Current Lost Revenue [Sum]*: <code>SELECT Current Amount [Sum] WHERE Status = Lost</code>

Think about this data model design when you are creating the 6th data dimension in your project. ;-)
